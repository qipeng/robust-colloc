---
title: "Robust Collocation Extraction"
author: "Peng Qi & Ruoqing Jiang"
output: html_document
---

Set up some basic variables. `map` is the mapping from indices to words, `corpus` is the corpus we will be working with, `V` is the vocabulary size (i.e. number of distinct words). `IJ[k,]` stores the indices of the first and second words in the bigram indexed `k`, and `idxlookup` is a lookup table that yields this index given the two words' indices.
```{r}
library(Matrix)
library(plyr)

if (file.exists('setup.RData')) {
  load('setup.RData')
} else {
  map = read.table("nyt/nyt_eng_200812.map", quote="")
  
  inds = read.table("nyt/nyt_eng_200812.ind")
  corpus = simplify2array(inds)
  
  n<-length(corpus)-1
  V<-length(unique(corpus))
  
  IJ = matrix(0, n, 2)
  
  for (i in 1:n) {
    IJ[i,] = corpus[i:(i+1)]
  }
  IJ = data.frame(IJ)
  IJ = ddply(IJ, .(IJ$X1, IJ$X2), nrow)
  IJ = simplify2array(IJ)[,2:1]
  
  npairs = dim(IJ)[1]
  
  idxlookup = sparseMatrix(i = IJ[,1], j = IJ[,2], x = 1:npairs, dims = c(V, V))
  
  save(map, corpus, V, IJ, npairs, idxlookup, file = 'setup.RData')
}

print(sprintf("# Words: %d", length(corpus)))
print(sprintf("# Unique Words: %d", V))
print(sprintf("# Unique Bigrams: %d", npairs))
```
More setup: count frequencies of words (`frequency`) and bigrams (`nfrequency`).
```{r}
count_freqs = function(corpus, idxlookup, IJ, V) {
  # This function has been optimized for performance.
  # Using for loops too much will be impossibly slow.
  npairs = dim(IJ)[1]
  n = length(corpus)
  
  IJ1 = matrix(0, n-1, 2)
  for (i in 1:(n-1)) {
    IJ1[i,] = corpus[i:(i+1)]
  }
  IJ1 = data.frame(IJ1)
  IJ1 = ddply(IJ1, .(IJ1$X1, IJ1$X2), nrow)
  IJ1 = simplify2array(IJ1)
  
  nfrequency = rep(0, npairs)
  nfrequency[idxlookup[IJ1[,2:1]]] = IJ1[,3]
  
  frequency = rep(0, V)
  counts = table(corpus[1:(n-1)])
  frequency[as.numeric(rownames(counts))] = counts
  
  res = list()
  res$nfrequency = nfrequency
  res$frequency = frequency
  res
}

if (file.exists('setup2.RData')) {
  load('setup2.RData')
} else {
  res = count_freqs(corpus, idxlookup, IJ, V)
  nfrequency = res$nfrequency
  frequency = res$frequency
  
  save(nfrequency, frequency, file = 'setup2.RData')
}
```
Last bit of setup: build language model by MLE.
```{r}
if (file.exists('setup3.RData')) {
  load('setup3.RData')
} else {
  conditional = rep(0, npairs)
  
  conditional[idxlookup[IJ]] = nfrequency[idxlookup[IJ]] / frequency[IJ[,2]]
  save(conditional, file = 'setup3.RData')
}
```
For efficient sampling from the languge model (conditional distributions), we implemented samplers with the [alias method](https://en.wikipedia.org/wiki/Alias_method).
```{r}
library(hash)

if (file.exists('samplers.RData')) {
  load('samplers.RData')
} else {
  # initialize multinomial samplers using alias method
  x = hash()
  J = hash()
  q = hash()
  
  for (i in 1:V) {
    x[i] = which(idxlookup[,i] > 0, arr.ind = T)
    probs = conditional[idxlookup[,i]]
    K = length(probs)
    qq = rep(0, K)
    JJ = rep(0, K)
    
    smaller = c()
    larger = c()
    for (j in 1:K) {
      qq[j] = K * probs[j]
      JJ[j] = j
      if (qq[j] < 1) {
        smaller = append(smaller, j)
      } else {
        larger = append(larger, j)
      }
    }
    
    while (length(smaller) > 0 && length(larger) > 0) {
      small = smaller[1]; smaller = smaller[-1];
      large = larger[1]; larger = larger[-1];
      
      JJ[small] = large
      qq[large] = qq[large] + qq[small] - 1.0
      
      if (qq[large] < 1.0) {
        smaller = append(smaller, large)
      } else {
        larger = append(larger, large)
      }
    }
    
    q[i] = qq
    J[i] = JJ
  }
  save(x, J, q, file = 'samplers.RData')
}

draw.alias = function(keyi) {
  xx = x[[keyi]] 
  JJ = J[[keyi]]
  qq = q[[keyi]]
  K = length(xx)
  k = sample.int(K, 1)
  if (runif(1) >= qq[k]) {
    return(xx[JJ[k]])
  } else {
    return(xx[k])
  }
}
```
Important functions: 
  
* `draw.sample` defines how we are drawing Markov chain bootstrap samples given the transition probabilities `conditional` and sample length `size`;
* `PMIfamily` computes multiple PMI-related statistics given a corpus, sharing the collection of sufficient statistics among these to save computational time.
* `PMI`, `PMIsq`, and `NMPI` implements point-wise mutual information, a modified PMI$^2$, and NPMI, respectively.
```{r}
draw.sample<-function(conditional,size,RNG=.Random.seed) {
  # parallel doesn't like cross-interferring random streams, so we set the random stream for each worker separately
  set.seed(RNG)
  
  new<-rep(0,size)
  new[1]<-1
  mp = hash()
  mx = hash()
  
  for (i in 2:size) {
    lastkey = as.character(new[i-1])
    new[i] = draw.alias(lastkey)
  }
  
  return(new)
}

PMI = function(probw1w2, probw1, probw2) {
  if (probw1w2 == 0) {
    probw1w2 = 1e-100
  }
  if ((probw1!=0)&&(probw2!=0)) {
    res = log(probw1w2/(probw1*probw2))
  } else {
    res = NaN
  }
  res
}

PMIsq = function(probw1w2, probw1, probw2) {
  if (probw1w2 == 0) {
    probw1w2 = 1e-100
  }
  if ((probw1!=0)&&(probw2!=0)) {
    res = log(probw1w2^2/(probw1*probw2)) / log(probw1w2)
  } else {
    res = NaN
  }
  res
}

NPMI = function(probw1w2, probw1, probw2) {
  if (probw1w2 == 0) {
    probw1w2 = 1e-100
  }
  if ((probw1!=0)&&(probw2!=0)) {
    res = log(probw1w2/(probw1*probw2)) / -log(probw1w2)
  } else {
    res = NaN
  }
  res
}

PMIfamily<-function(functions, corpus, V, idxlookup, IJ) {
  npairs = dim(IJ)[1]
  n = length(corpus)
  res = count_freqs(corpus, idxlookup, IJ, V)
  nfrequency = res$nfrequency
  frequency = res$frequency
  
  nprob = nfrequency / (n - 1)
  prob = frequency / n
  
  res = matrix(0, npairs, length(functions))
  for(i in 1:npairs) {
    w1 = IJ[i,1]
    w2 = IJ[i,2]
    for (j in 1:length(functions)) {
      res[i, j] = functions[[j]](nprob[i], prob[w1], prob[w2])
    }
  }
  res
}
```
Compute statistics on the original corpus.
```{r}
stat_names = c('PMI', 'PMI^2*', 'NPMI')
perplexity = function(conditional, corpus, idxlookup) {
  n = length(corpus)
  exp(mean(log(1 / conditional[idxlookup[cbind(corpus[2:n], corpus[1:(n-1)])]])))
}
if (file.exists('vanilla.RData')) {
  load('vanilla.RData')
} else {
  vanilla_res = PMIfamily(c(PMI, PMIsq, NPMI), corpus, V, idxlookup, IJ)
  ppl = perplexity(conditional, corpus, idxlookup)
  save(vanilla_res, ppl, file = 'vanilla.RData')
}
vanilla_res[1:10,]
print(sprintf('The perplexity of the MLE language model is: %f', ppl))
```
Finally, run bootstrap!
```{r}
if (file.exists('bootstrap.RData')) {
  load('bootstrap.RData')
} else {
  library(parallel)
  
  CORES = 8
  SAMPLES = 200
  
  # set up RNGs
  RNGkind("L'Ecuyer-CMRG")
  set.seed(31415)
  ## start M workers
  s <- .Random.seed
  RNG = list()
  for (i in 1:SAMPLES) {
    s <- nextRNGStream(s)
    RNG[[i]] = s
  }
  
  bootstrap_res = simplify2array(mclapply(1:SAMPLES, function(i) PMIfamily(c(PMI, PMIsq, NPMI), draw.sample(conditional, length(corpus), RNG[[i]]),V,idxlookup,IJ), mc.cores = CORES))
  save(bootstrap_res, file = "bootstrap.RData")
}
```